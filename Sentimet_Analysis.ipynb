{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuanMinhLuu/ADS-Submission-Final-Report/blob/main/Sentimet_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and install missing packages\n",
        "import pandas as pd\n",
        "import re\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8_mFlfYVwYu",
        "outputId": "e9ead41c-05cd-4a83-d9cb-4003bd08125b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data"
      ],
      "metadata": {
        "id": "KEVVfMaT7urC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to my Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqrqWsCGWXrc",
        "outputId": "a6a4c380-956b-44d7-dded-18a7d18ea72e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path to the dataset containing news\n",
        "file_path = '/content/drive/My Drive/Sentiment_Analysis/bbc_news.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7GS3pVNWaFA",
        "outputId": "1d3e982d-cdea-45d3-af41-05d04d03b0e3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                     title  \\\n",
            "0                Ukraine: Angry Zelensky vows to punish Russian atrocities   \n",
            "1                      War in Ukraine: Taking cover in a town under attack   \n",
            "2                               Ukraine war 'catastrophic for global food'   \n",
            "3  Manchester Arena bombing: Saffie Roussos's parents on hearing the truth   \n",
            "4            Ukraine conflict: Oil price soars to highest level since 2008   \n",
            "\n",
            "                         pubDate  \\\n",
            "0  Mon, 07 Mar 2022 08:01:56 GMT   \n",
            "1  Sun, 06 Mar 2022 22:49:58 GMT   \n",
            "2  Mon, 07 Mar 2022 00:14:42 GMT   \n",
            "3  Mon, 07 Mar 2022 00:05:40 GMT   \n",
            "4  Mon, 07 Mar 2022 08:15:53 GMT   \n",
            "\n",
            "                                               guid  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-60638042   \n",
            "1  https://www.bbc.co.uk/news/world-europe-60641873   \n",
            "2      https://www.bbc.co.uk/news/business-60623941   \n",
            "3            https://www.bbc.co.uk/news/uk-60579079   \n",
            "4      https://www.bbc.co.uk/news/business-60642786   \n",
            "\n",
            "                                                                                 link  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-60638042?at_medium=RSS&at_campaign=KARANGA   \n",
            "1  https://www.bbc.co.uk/news/world-europe-60641873?at_medium=RSS&at_campaign=KARANGA   \n",
            "2      https://www.bbc.co.uk/news/business-60623941?at_medium=RSS&at_campaign=KARANGA   \n",
            "3            https://www.bbc.co.uk/news/uk-60579079?at_medium=RSS&at_campaign=KARANGA   \n",
            "4      https://www.bbc.co.uk/news/business-60642786?at_medium=RSS&at_campaign=KARANGA   \n",
            "\n",
            "                                                                                              description  \n",
            "0     The Ukrainian president says the country will not forgive or forget those who murder its civilians.  \n",
            "1  Jeremy Bowen was on the frontline in Irpin, as residents came under Russian fire while trying to flee.  \n",
            "2   One of the world's biggest fertiliser firms says the conflict could deliver a shock to food supplies.  \n",
            "3    The parents of the Manchester Arena bombing's youngest victim speak about their life since she died.  \n",
            "4        Consumers are feeling the impact of higher energy costs as fuel prices and household bills jump.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply basic cleaning to the title and description columns\n",
        "df['title_cleaned'] = df['title'].apply(clean_text)\n",
        "df['description_cleaned'] = df['description'].apply(clean_text)\n",
        "\n",
        "# Define stop words and a function to remove them\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "# Apply stopwords removal to the cleaned columns\n",
        "df['title_cleaned'] = df['title_cleaned'].apply(remove_stopwords)\n",
        "df['description_cleaned'] = df['description_cleaned'].apply(remove_stopwords)\n",
        "\n",
        "# Initialize the WordNetLemmatizer and define a function to lemmatize text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization to the cleaned columns\n",
        "df['title_cleaned'] = df['title_cleaned'].apply(lemmatize_text)\n",
        "df['description_cleaned'] = df['description_cleaned'].apply(lemmatize_text)\n",
        "\n",
        "# Filter out rows where the cleaned text is too short\n",
        "df = df[df['title_cleaned'].apply(lambda x: len(x.split()) > 2)]\n",
        "df = df[df['description_cleaned'].apply(lambda x: len(x.split()) > 2)]\n",
        "\n",
        "# Remove rows where the cleaned text length is below a reasonable threshold\n",
        "df = df[(df['title_cleaned'].str.len() > 10) & (df['description_cleaned'].str.len() > 10)]\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to classify sentiment using VADER based on combined title and description content\n",
        "def get_vader_combined_sentiment(title, description):\n",
        "    title_score = analyzer.polarity_scores(title)['compound']\n",
        "    description_score = analyzer.polarity_scores(description)['compound']\n",
        "    avg_score = (title_score + description_score) / 2\n",
        "\n",
        "    if avg_score >= 0.05:\n",
        "        return '__label__positive'\n",
        "    elif avg_score <= -0.05:\n",
        "        return '__label__negative'\n",
        "    else:\n",
        "        return '__label__neutral'\n",
        "\n",
        "# Apply VADER sentiment classification to the cleaned title and description columns\n",
        "df['combined_sentiment'] = df.apply(lambda x: get_vader_combined_sentiment(x['title_cleaned'], x['description_cleaned']), axis=1)\n",
        "\n",
        "# Format the cleaned data for FastText\n",
        "df['combined_fasttext_format_cleaned'] = df['combined_sentiment'] + \" \" + df['description_cleaned']\n",
        "\n",
        "# Save the cleaned dataset to a file\n",
        "output_file = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_combined_fasttext_cleaned.txt'\n",
        "df['combined_fasttext_format_cleaned'].to_csv(output_file, index=False, header=False)\n",
        "\n",
        "# Display the first few rows of the cleaned and formatted data\n",
        "print(\"Cleaned Combined Sentiment Data:\")\n",
        "print(df[['title_cleaned', 'description_cleaned', 'combined_sentiment', 'combined_fasttext_format_cleaned']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbAVExZEWkgx",
        "outputId": "733f541c-19c0-4624-8309-b0c1ecf6c16f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Combined Sentiment Data:\n",
            "                                                   title_cleaned  \\\n",
            "0             ukraine angry zelensky vow punish russian atrocity   \n",
            "1                           war ukraine taking cover town attack   \n",
            "2                           ukraine war catastrophic global food   \n",
            "3  manchester arena bombing saffie roussoss parent hearing truth   \n",
            "4       ukraine conflict oil price soar highest level since 2008   \n",
            "\n",
            "                                                              description_cleaned  \\\n",
            "0                  ukrainian president say country forgive forget murder civilian   \n",
            "1             jeremy bowen frontline irpin resident came russian fire trying flee   \n",
            "2  one world biggest fertiliser firm say conflict could deliver shock food supply   \n",
            "3           parent manchester arena bombing youngest victim speak life since died   \n",
            "4       consumer feeling impact higher energy cost fuel price household bill jump   \n",
            "\n",
            "  combined_sentiment  \\\n",
            "0  __label__negative   \n",
            "1  __label__negative   \n",
            "2  __label__negative   \n",
            "3  __label__negative   \n",
            "4   __label__neutral   \n",
            "\n",
            "                                                                   combined_fasttext_format_cleaned  \n",
            "0                  __label__negative ukrainian president say country forgive forget murder civilian  \n",
            "1             __label__negative jeremy bowen frontline irpin resident came russian fire trying flee  \n",
            "2  __label__negative one world biggest fertiliser firm say conflict could deliver shock food supply  \n",
            "3           __label__negative parent manchester arena bombing youngest victim speak life since died  \n",
            "4        __label__neutral consumer feeling impact higher energy cost fuel price household bill jump  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the distribution of sentiment classes\n",
        "print(\"Class Distribution in Combined Sentiment Data:\")\n",
        "print(df['combined_sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzuR1hEXWoyU",
        "outputId": "20452f90-9a42-4c57-956f-4fe26ac86e26"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution in Combined Sentiment Data:\n",
            "combined_sentiment\n",
            "__label__negative    17801\n",
            "__label__positive    14401\n",
            "__label__neutral      7077\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the combined data into training (80%) and testing (20%) sets.\n",
        "train_data, test_data = train_test_split(df['combined_fasttext_format_cleaned'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the training and testing datasets to separate files.\n",
        "train_data.to_csv('/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt', index=False, header=False)\n",
        "test_data.to_csv('/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt', index=False, header=False)\n",
        "\n",
        "# Display the sizes of the training and testing sets.\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Testing set size: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_CMfdz1XSbZ",
        "outputId": "6f5aba78-75b9-474a-baab-59816885a098"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 31423\n",
            "Testing set size: 7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "# Train the FastText model using the training dataset.\n",
        "model = fasttext.train_supervised(\n",
        "    input='/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt',\n",
        "    lr=1.0,\n",
        "    epoch=25,\n",
        "    wordNgrams=2,\n",
        "    verbose=2,\n",
        "    minCount=1\n",
        ")\n",
        "\n",
        "# Save the trained model to a file.\n",
        "model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_model_combined.bin')\n",
        "print(\"Model trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_kioV1XiOF",
        "outputId": "8f4725a4-da0e-4c76-b3af-89af48750120"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "result = model.test('/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt')\n",
        "\n",
        "# Display evaluation metrics.\n",
        "print(f\"Number of examples: {result[0]}\")\n",
        "print(f\"Precision: {result[1]}\")\n",
        "print(f\"Recall: {result[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HagMaY0yXnNQ",
        "outputId": "d457a838-9d4c-408e-d362-14d79f902e3f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples: 7856\n",
            "Precision: 0.7368890020366599\n",
            "Recall: 0.7368890020366599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for evaluation\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load the test dataset with labels\n",
        "test_file_path = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt'\n",
        "\n",
        "# Read the test data\n",
        "test_data = pd.read_csv(test_file_path, header=None, names=['text'])\n",
        "\n",
        "# Extract labels and separate text\n",
        "test_data['label'] = test_data['text'].apply(lambda x: x.split()[0])\n",
        "test_data['text_only'] = test_data['text'].apply(lambda x: ' '.join(x.split()[1:]))\n",
        "\n",
        "# Get predictions for the test dataset\n",
        "predictions = [model.predict(row)[0][0] for row in test_data['text_only']]\n",
        "\n",
        "# Calculate and display the confusion matrix\n",
        "conf_matrix = confusion_matrix(test_data['label'], predictions, labels=['__label__negative', '__label__neutral', '__label__positive'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Display the classification report including precision, recall, and F1-score\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_data['label'], predictions, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kAiUsV3YlJl",
        "outputId": "7e9551fe-48e3-4d2b-a5f2-15fe20c2f07a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2917  252  385]\n",
            " [ 449  619  367]\n",
            " [ 369  245 2253]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.78      0.82      0.80      3554\n",
            "     Neutral       0.55      0.43      0.49      1435\n",
            "    Positive       0.75      0.79      0.77      2867\n",
            "\n",
            "    accuracy                           0.74      7856\n",
            "   macro avg       0.70      0.68      0.68      7856\n",
            "weighted avg       0.73      0.74      0.73      7856\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "learning_rates = [0.01, 0.05, 0.1]\n",
        "epochs = [25, 50]\n",
        "word_ngrams = [1, 2]\n",
        "dimensions = [50, 100]\n",
        "\n",
        "# Variables to track the best model and its performance\n",
        "best_precision = 0\n",
        "best_model = None\n",
        "best_params = {}\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for epoch in epochs:\n",
        "        for ngram in word_ngrams:\n",
        "            for dim in dimensions:\n",
        "                print(f\"Training model with lr={lr}, epoch={epoch}, wordNgrams={ngram}, dim={dim}\")\n",
        "\n",
        "                try:\n",
        "                    # Train the FastText model with the current hyperparameters\n",
        "                    model = fasttext.train_supervised(\n",
        "                        input='/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt',\n",
        "                        lr=lr,\n",
        "                        epoch=epoch,\n",
        "                        wordNgrams=ngram,\n",
        "                        dim=dim,\n",
        "                        verbose=2,\n",
        "                        minCount=1\n",
        "                    )\n",
        "\n",
        "                    # Get predictions for the test dataset\n",
        "                    predictions = [model.predict(row)[0][0] for row in test_data['text_only']]\n",
        "\n",
        "                    # Calculate the precision for the current model\n",
        "                    precision = classification_report(\n",
        "                        test_data['label'], predictions, output_dict=True\n",
        "                    )['weighted avg']['precision']\n",
        "\n",
        "                    print(f\"Precision: {precision}\")\n",
        "\n",
        "                    # Update the best model if the current one outperforms previous ones\n",
        "                    if precision > best_precision:\n",
        "                        best_precision = precision\n",
        "                        best_model = model\n",
        "                        best_params = {'lr': lr, 'epoch': epoch, 'wordNgrams': ngram, 'dim': dim}\n",
        "                        print(f\"New best model found with precision: {best_precision} and parameters: {best_params}\")\n",
        "                except RuntimeError as error:\n",
        "                    print(f\"Error encountered with parameters: lr={lr}, epoch={epoch}, wordNgrams={ngram}, dim={dim}\")\n",
        "                    print(f\"RuntimeError: {error}\")\n",
        "                    continue\n",
        "\n",
        "# Save the best model if found\n",
        "if best_model:\n",
        "    best_model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_best_tuned_model.bin')\n",
        "    print(f\"Best model saved with parameters: {best_params} and precision: {best_precision}\")\n",
        "else:\n",
        "    print(\"No suitable model was found during hyperparameter tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0MUWv5_he4W",
        "outputId": "0b9829ee-0d40-4373-f063-4210fb03009b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with lr=0.01, epoch=25, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.01, epoch=25, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.01, epoch=25, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7050998341140617\n",
            "New best model found with precision: 0.7050998341140617 and parameters: {'lr': 0.01, 'epoch': 25, 'wordNgrams': 2, 'dim': 50}\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.7058740050282146\n",
            "New best model found with precision: 0.7058740050282146 and parameters: {'lr': 0.01, 'epoch': 25, 'wordNgrams': 2, 'dim': 100}\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.01, epoch=50, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.01, epoch=50, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7326003520497344\n",
            "New best model found with precision: 0.7326003520497344 and parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 50}\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7339488060368151\n",
            "New best model found with precision: 0.7339488060368151 and parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 100}\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.05, epoch=25, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.05, epoch=25, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7298998502010393\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.731060904783669\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.05, epoch=50, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.05, epoch=50, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7290676508051578\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7298938209057386\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.1, epoch=25, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.1, epoch=25, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7285941887909699\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.7295938690940336\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.1, epoch=50, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=1, dim=100\n",
            "Error encountered with parameters: lr=0.1, epoch=50, wordNgrams=1, dim=100\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7286576179459908\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7286422474542986\n",
            "Best model saved with parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 100} and precision: 0.7339488060368151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate the classes into different dataframes\n",
        "df_negative = df[df['combined_sentiment'] == '__label__negative']\n",
        "df_positive = df[df['combined_sentiment'] == '__label__positive']\n",
        "df_neutral = df[df['combined_sentiment'] == '__label__neutral']\n",
        "\n",
        "# Determine the target size for oversampling (same as the positive class size)\n",
        "target_size = len(df_positive)\n",
        "\n",
        "# Perform random oversampling on the neutral class to reach the target size\n",
        "df_neutral_upsampled = resample(df_neutral,\n",
        "                                replace=True,\n",
        "                                n_samples=target_size,\n",
        "                                random_state=42)\n",
        "\n",
        "# Combine the oversampled neutral class with the original positive and negative classes\n",
        "df_balanced = pd.concat([df_negative, df_positive, df_neutral_upsampled])\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(\"Class Distribution After Oversampling Neutral Class:\")\n",
        "print(df_balanced['combined_sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1zzkblB2OPV",
        "outputId": "84a62292-5b54-49ca-a5fc-547acb0b2769"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution After Oversampling Neutral Class:\n",
            "combined_sentiment\n",
            "__label__negative    17801\n",
            "__label__positive    14401\n",
            "__label__neutral     14401\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the balanced dataset to a file\n",
        "balanced_output_file = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_balanced_combined.txt'\n",
        "df_balanced['combined_fasttext_format_cleaned'].to_csv(balanced_output_file, index=False, header=False)"
      ],
      "metadata": {
        "id": "Y4-CRg9O3Yoa"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the FastText model using the balanced dataset\n",
        "balanced_model = fasttext.train_supervised(\n",
        "    input=balanced_output_file,\n",
        "    lr=1.0,\n",
        "    epoch=25,\n",
        "    wordNgrams=2,\n",
        "    verbose=2,\n",
        "    minCount=1\n",
        ")\n",
        "\n",
        "# Save the balanced-trained model to a file\n",
        "balanced_model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_balanced_model.bin')\n",
        "print(\"Balanced model trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVxDV2H-39g5",
        "outputId": "f405e401-b798-4f73-d97c-fa4af69f03a2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions using the balanced model on the test dataset\n",
        "test_data['balanced_predictions'] = test_data['text_only'].apply(lambda x: balanced_model.predict(x)[0][0])\n",
        "\n",
        "# Generate the classification report with the predictions\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate the classification\n",
        "report = classification_report(test_data['label'], test_data['balanced_predictions'], target_names=['Negative', 'Neutral', 'Positive'], output_dict=True)\n",
        "\n",
        "# Extract the weighted precision and recall\n",
        "overall_precision = report['weighted avg']['precision']\n",
        "overall_recall = report['weighted avg']['recall']\n",
        "\n",
        "# Display the overall precision and recall\n",
        "print(f\"Overall Precision: {overall_precision}\")\n",
        "print(f\"Overall Recall: {overall_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9qeBbIq5YJa",
        "outputId": "15c1cac9-7b75-4b7c-c38e-e8f5cb85c905"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Precision: 0.9810387925588343\n",
            "Overall Recall: 0.9810336048879837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Get predictions for the test set\n",
        "test_data['balanced_predictions'] = test_data['text_only'].apply(lambda x: balanced_model.predict(x)[0][0])\n",
        "\n",
        "# Calculate and display the confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(test_data['label'], test_data['balanced_predictions'],\n",
        "                               labels=['__label__negative', '__label__neutral', '__label__positive'])\n",
        "print(\"Confusion Matrix After Balancing:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification report (includes F1-score)\n",
        "print(\"\\nClassification Report After Balancing:\")\n",
        "print(classification_report(test_data['label'], test_data['balanced_predictions'],\n",
        "                            target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi-q5Qr63-9d",
        "outputId": "d7012c4d-eca6-4390-8ae3-f049428969ca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix After Balancing:\n",
            "[[3539   13    2]\n",
            " [  63 1319   53]\n",
            " [   6   12 2849]]\n",
            "\n",
            "Classification Report After Balancing:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.98      1.00      0.99      3554\n",
            "     Neutral       0.98      0.92      0.95      1435\n",
            "    Positive       0.98      0.99      0.99      2867\n",
            "\n",
            "    accuracy                           0.98      7856\n",
            "   macro avg       0.98      0.97      0.97      7856\n",
            "weighted avg       0.98      0.98      0.98      7856\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMupeo0AvnbpTgN4yjfVeBS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}