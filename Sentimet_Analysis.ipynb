{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TuanMinhLuu/ADS-Submission-Final-Report/blob/main/Sentimet_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and install missing packages\n",
        "!pip install fasttext pandas numpy textblob\n",
        "!pip install vaderSentiment\n",
        "import pandas as pd\n",
        "import re\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8_mFlfYVwYu",
        "outputId": "c3d887c3-d97a-47ab-d8ac-e340a39e852a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/73.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp310-cp310-linux_x86_64.whl size=4296187 sha256=89029f26c99245e1aafe5bfe3f902f1a0ec777aca9510ac8b21c0ffdb7e6ec11\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/a2/00/81db54d3e6a8199b829d58e02cec2ddb20ce3e59fad8d3c92a\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-2.13.6\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data"
      ],
      "metadata": {
        "id": "KEVVfMaT7urC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to my Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqrqWsCGWXrc",
        "outputId": "fa810399-0030-415f-bab1-12e8da320b88"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the file path to the dataset containing news\n",
        "file_path = '/content/drive/My Drive/Sentiment_Analysis/bbc_news.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7GS3pVNWaFA",
        "outputId": "0e2af28c-40f7-49ee-cc37-4d88a55ed351"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  Ukraine: Angry Zelensky vows to punish Russian...   \n",
            "1  War in Ukraine: Taking cover in a town under a...   \n",
            "2         Ukraine war 'catastrophic for global food'   \n",
            "3  Manchester Arena bombing: Saffie Roussos's par...   \n",
            "4  Ukraine conflict: Oil price soars to highest l...   \n",
            "\n",
            "                         pubDate  \\\n",
            "0  Mon, 07 Mar 2022 08:01:56 GMT   \n",
            "1  Sun, 06 Mar 2022 22:49:58 GMT   \n",
            "2  Mon, 07 Mar 2022 00:14:42 GMT   \n",
            "3  Mon, 07 Mar 2022 00:05:40 GMT   \n",
            "4  Mon, 07 Mar 2022 08:15:53 GMT   \n",
            "\n",
            "                                               guid  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-60638042   \n",
            "1  https://www.bbc.co.uk/news/world-europe-60641873   \n",
            "2      https://www.bbc.co.uk/news/business-60623941   \n",
            "3            https://www.bbc.co.uk/news/uk-60579079   \n",
            "4      https://www.bbc.co.uk/news/business-60642786   \n",
            "\n",
            "                                                link  \\\n",
            "0  https://www.bbc.co.uk/news/world-europe-606380...   \n",
            "1  https://www.bbc.co.uk/news/world-europe-606418...   \n",
            "2  https://www.bbc.co.uk/news/business-60623941?a...   \n",
            "3  https://www.bbc.co.uk/news/uk-60579079?at_medi...   \n",
            "4  https://www.bbc.co.uk/news/business-60642786?a...   \n",
            "\n",
            "                                         description  \n",
            "0  The Ukrainian president says the country will ...  \n",
            "1  Jeremy Bowen was on the frontline in Irpin, as...  \n",
            "2  One of the world's biggest fertiliser firms sa...  \n",
            "3  The parents of the Manchester Arena bombing's ...  \n",
            "4  Consumers are feeling the impact of higher ene...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function to clean and preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply basic cleaning to the title and description columns\n",
        "df['title_cleaned'] = df['title'].apply(clean_text)\n",
        "df['description_cleaned'] = df['description'].apply(clean_text)\n",
        "\n",
        "# Define stop words and a function to remove them\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "# Apply stopwords removal to the cleaned columns\n",
        "df['title_cleaned'] = df['title_cleaned'].apply(remove_stopwords)\n",
        "df['description_cleaned'] = df['description_cleaned'].apply(remove_stopwords)\n",
        "\n",
        "# Initialize the WordNetLemmatizer and define a function to lemmatize text\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization to the cleaned columns\n",
        "df['title_cleaned'] = df['title_cleaned'].apply(lemmatize_text)\n",
        "df['description_cleaned'] = df['description_cleaned'].apply(lemmatize_text)\n",
        "\n",
        "# Filter out rows where the cleaned text is too short\n",
        "df = df[df['title_cleaned'].apply(lambda x: len(x.split()) > 2)]\n",
        "df = df[df['description_cleaned'].apply(lambda x: len(x.split()) > 2)]\n",
        "\n",
        "# Remove rows where the cleaned text length is below a reasonable threshold\n",
        "df = df[(df['title_cleaned'].str.len() > 10) & (df['description_cleaned'].str.len() > 10)]\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function to classify sentiment using VADER based on combined title and description content\n",
        "def get_vader_combined_sentiment(title, description):\n",
        "    title_score = analyzer.polarity_scores(title)['compound']\n",
        "    description_score = analyzer.polarity_scores(description)['compound']\n",
        "    avg_score = (title_score + description_score) / 2\n",
        "\n",
        "    if avg_score >= 0.05:\n",
        "        return '__label__positive'\n",
        "    elif avg_score <= -0.05:\n",
        "        return '__label__negative'\n",
        "    else:\n",
        "        return '__label__neutral'\n",
        "\n",
        "# Apply VADER sentiment classification to the cleaned title and description columns\n",
        "df['combined_sentiment'] = df.apply(lambda x: get_vader_combined_sentiment(x['title_cleaned'], x['description_cleaned']), axis=1)\n",
        "\n",
        "# Format the cleaned data for FastText\n",
        "df['combined_fasttext_format_cleaned'] = df['combined_sentiment'] + \" \" + df['description_cleaned']\n",
        "\n",
        "# Save the cleaned dataset to a file\n",
        "output_file = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_combined_fasttext_cleaned.txt'\n",
        "df['combined_fasttext_format_cleaned'].to_csv(output_file, index=False, header=False)\n",
        "\n",
        "# Display the first few rows of the cleaned and formatted data\n",
        "print(\"Cleaned Combined Sentiment Data:\")\n",
        "print(df[['title_cleaned', 'description_cleaned', 'combined_sentiment', 'combined_fasttext_format_cleaned']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbAVExZEWkgx",
        "outputId": "dbb6f7fe-dd09-4ab6-b928-f2654eb4c24d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Combined Sentiment Data:\n",
            "                                       title_cleaned  \\\n",
            "0  ukraine angry zelensky vow punish russian atro...   \n",
            "1               war ukraine taking cover town attack   \n",
            "2               ukraine war catastrophic global food   \n",
            "3  manchester arena bombing saffie roussoss paren...   \n",
            "4  ukraine conflict oil price soar highest level ...   \n",
            "\n",
            "                                 description_cleaned combined_sentiment  \\\n",
            "0  ukrainian president say country forgive forget...  __label__negative   \n",
            "1  jeremy bowen frontline irpin resident came rus...  __label__negative   \n",
            "2  one world biggest fertiliser firm say conflict...  __label__negative   \n",
            "3  parent manchester arena bombing youngest victi...  __label__negative   \n",
            "4  consumer feeling impact higher energy cost fue...   __label__neutral   \n",
            "\n",
            "                    combined_fasttext_format_cleaned  \n",
            "0  __label__negative ukrainian president say coun...  \n",
            "1  __label__negative jeremy bowen frontline irpin...  \n",
            "2  __label__negative one world biggest fertiliser...  \n",
            "3  __label__negative parent manchester arena bomb...  \n",
            "4  __label__neutral consumer feeling impact highe...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the distribution of sentiment classes\n",
        "print(\"Class Distribution in Combined Sentiment Data:\")\n",
        "print(df['combined_sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzuR1hEXWoyU",
        "outputId": "c8d13cc5-e7a5-4590-f3fe-b70cd923af9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution in Combined Sentiment Data:\n",
            "combined_sentiment\n",
            "__label__negative    17801\n",
            "__label__positive    14401\n",
            "__label__neutral      7077\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the combined data into training (80%) and testing (20%) sets.\n",
        "train_data, test_data = train_test_split(df['combined_fasttext_format_cleaned'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the training and testing datasets to separate files.\n",
        "train_data.to_csv('/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt', index=False, header=False)\n",
        "test_data.to_csv('/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt', index=False, header=False)\n",
        "\n",
        "# Display the sizes of the training and testing sets.\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Testing set size: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_CMfdz1XSbZ",
        "outputId": "83a92207-d75a-48e8-b8b9-c2c4e2e313e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 31423\n",
            "Testing set size: 7856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "# Train the FastText model using the training dataset.\n",
        "model = fasttext.train_supervised(\n",
        "    input='/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt',\n",
        "    lr=1.0,\n",
        "    epoch=25,\n",
        "    wordNgrams=2,\n",
        "    verbose=2,\n",
        "    minCount=1\n",
        ")\n",
        "\n",
        "# Save the trained model to a file.\n",
        "model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_model_combined.bin')\n",
        "print(\"Model trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_kioV1XiOF",
        "outputId": "79181d24-b057-4367-91a3-ae57970e85ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset.\n",
        "result = model.test('/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt')\n",
        "\n",
        "# Display evaluation metrics.\n",
        "print(f\"Number of examples: {result[0]}\")\n",
        "print(f\"Precision: {result[1]}\")\n",
        "print(f\"Recall: {result[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HagMaY0yXnNQ",
        "outputId": "75baa1c7-a665-4fac-a2ab-08932b42236e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples: 7856\n",
            "Precision: 0.7368890020366599\n",
            "Recall: 0.7368890020366599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for evaluation\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load the test dataset with labels\n",
        "test_file_path = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_test_combined.txt'\n",
        "\n",
        "# Read the test data\n",
        "test_data = pd.read_csv(test_file_path, header=None, names=['text'])\n",
        "\n",
        "# Extract labels and separate text\n",
        "test_data['label'] = test_data['text'].apply(lambda x: x.split()[0])\n",
        "test_data['text_only'] = test_data['text'].apply(lambda x: ' '.join(x.split()[1:]))\n",
        "\n",
        "# Get predictions for the test dataset\n",
        "predictions = [model.predict(row)[0][0] for row in test_data['text_only']]\n",
        "\n",
        "# Calculate and display the confusion matrix\n",
        "conf_matrix = confusion_matrix(test_data['label'], predictions, labels=['__label__negative', '__label__neutral', '__label__positive'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Display the classification report including precision, recall, and F1-score\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_data['label'], predictions, target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kAiUsV3YlJl",
        "outputId": "b0baeb81-67c9-475f-dc5b-ef457c976ce6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2917  252  385]\n",
            " [ 449  619  367]\n",
            " [ 369  245 2253]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.78      0.82      0.80      3554\n",
            "     Neutral       0.55      0.43      0.49      1435\n",
            "    Positive       0.75      0.79      0.77      2867\n",
            "\n",
            "    accuracy                           0.74      7856\n",
            "   macro avg       0.70      0.68      0.68      7856\n",
            "weighted avg       0.73      0.74      0.73      7856\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define hyperparameter grid for tuning\n",
        "learning_rates = [0.01, 0.05, 0.1]\n",
        "epochs = [25, 50]\n",
        "word_ngrams = [1, 2]\n",
        "dimensions = [50, 100]\n",
        "\n",
        "# Variables to track the best model and its performance\n",
        "best_precision = 0\n",
        "best_model = None\n",
        "best_params = {}\n",
        "\n",
        "# Iterate over all combinations of hyperparameters\n",
        "for lr in learning_rates:\n",
        "    for epoch in epochs:\n",
        "        for ngram in word_ngrams:\n",
        "            for dim in dimensions:\n",
        "                print(f\"Training model with lr={lr}, epoch={epoch}, wordNgrams={ngram}, dim={dim}\")\n",
        "\n",
        "                try:\n",
        "                    # Train the FastText model with the current hyperparameters\n",
        "                    model = fasttext.train_supervised(\n",
        "                        input='/content/drive/My Drive/Sentiment_Analysis/bbc_news_train_combined.txt',\n",
        "                        lr=lr,\n",
        "                        epoch=epoch,\n",
        "                        wordNgrams=ngram,\n",
        "                        dim=dim,\n",
        "                        verbose=2,\n",
        "                        minCount=1\n",
        "                    )\n",
        "\n",
        "                    # Get predictions for the test dataset\n",
        "                    predictions = [model.predict(row)[0][0] for row in test_data['text_only']]\n",
        "\n",
        "                    # Calculate the precision for the current model\n",
        "                    precision = classification_report(\n",
        "                        test_data['label'], predictions, output_dict=True\n",
        "                    )['weighted avg']['precision']\n",
        "\n",
        "                    print(f\"Precision: {precision}\")\n",
        "\n",
        "                    # Update the best model if the current one outperforms previous ones\n",
        "                    if precision > best_precision:\n",
        "                        best_precision = precision\n",
        "                        best_model = model\n",
        "                        best_params = {'lr': lr, 'epoch': epoch, 'wordNgrams': ngram, 'dim': dim}\n",
        "                        print(f\"New best model found with precision: {best_precision} and parameters: {best_params}\")\n",
        "                except RuntimeError as error:\n",
        "                    print(f\"Error encountered with parameters: lr={lr}, epoch={epoch}, wordNgrams={ngram}, dim={dim}\")\n",
        "                    print(f\"RuntimeError: {error}\")\n",
        "                    continue\n",
        "\n",
        "# Save the best model if found\n",
        "if best_model:\n",
        "    best_model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_best_tuned_model.bin')\n",
        "    print(f\"Best model saved with parameters: {best_params} and precision: {best_precision}\")\n",
        "else:\n",
        "    print(\"No suitable model was found during hyperparameter tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0MUWv5_he4W",
        "outputId": "a0f395fc-6a98-4645-b825-697d30e383cb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with lr=0.01, epoch=25, wordNgrams=1, dim=50\n",
            "Error encountered with parameters: lr=0.01, epoch=25, wordNgrams=1, dim=50\n",
            "RuntimeError: Encountered NaN.\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=1, dim=100\n",
            "Precision: 0.7247297954101589\n",
            "New best model found with precision: 0.7247297954101589 and parameters: {'lr': 0.01, 'epoch': 25, 'wordNgrams': 1, 'dim': 100}\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7050998341140617\n",
            "Training model with lr=0.01, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.7058740050282146\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=1, dim=50\n",
            "Precision: 0.7230775265966417\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=1, dim=100\n",
            "Precision: 0.7230856553265154\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7326003520497344\n",
            "New best model found with precision: 0.7326003520497344 and parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 50}\n",
            "Training model with lr=0.01, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7339488060368151\n",
            "New best model found with precision: 0.7339488060368151 and parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 100}\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=1, dim=50\n",
            "Precision: 0.7092942685933729\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=1, dim=100\n",
            "Precision: 0.7098748373202025\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7298998502010393\n",
            "Training model with lr=0.05, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.731060904783669\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=1, dim=50\n",
            "Precision: 0.6956828560111363\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=1, dim=100\n",
            "Precision: 0.6958033313621506\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7290676508051578\n",
            "Training model with lr=0.05, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7298938209057386\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=1, dim=50\n",
            "Precision: 0.6919378765193379\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=1, dim=100\n",
            "Precision: 0.6918406926446901\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=2, dim=50\n",
            "Precision: 0.7285941887909699\n",
            "Training model with lr=0.1, epoch=25, wordNgrams=2, dim=100\n",
            "Precision: 0.7295938690940336\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=1, dim=50\n",
            "Precision: 0.6872398552834778\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=1, dim=100\n",
            "Precision: 0.6873619356525994\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=2, dim=50\n",
            "Precision: 0.7286576179459908\n",
            "Training model with lr=0.1, epoch=50, wordNgrams=2, dim=100\n",
            "Precision: 0.7286422474542986\n",
            "Best model saved with parameters: {'lr': 0.01, 'epoch': 50, 'wordNgrams': 2, 'dim': 100} and precision: 0.7339488060368151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Separate the classes into different dataframes\n",
        "df_negative = df[df['combined_sentiment'] == '__label__negative']\n",
        "df_positive = df[df['combined_sentiment'] == '__label__positive']\n",
        "df_neutral = df[df['combined_sentiment'] == '__label__neutral']\n",
        "\n",
        "# Determine the target size for oversampling (same as the positive class size)\n",
        "target_size = len(df_positive)\n",
        "\n",
        "# Perform random oversampling on the neutral class to reach the target size\n",
        "df_neutral_upsampled = resample(df_neutral,\n",
        "                                replace=True,\n",
        "                                n_samples=target_size,\n",
        "                                random_state=42)\n",
        "\n",
        "# Combine the oversampled neutral class with the original positive and negative classes\n",
        "df_balanced = pd.concat([df_negative, df_positive, df_neutral_upsampled])\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(\"Class Distribution After Oversampling Neutral Class:\")\n",
        "print(df_balanced['combined_sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1zzkblB2OPV",
        "outputId": "f47bf1b2-7c4c-4870-fe20-4dee209b5d64"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution After Oversampling Neutral Class:\n",
            "combined_sentiment\n",
            "__label__negative    17801\n",
            "__label__positive    14401\n",
            "__label__neutral     14401\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the balanced dataset to a file\n",
        "balanced_output_file = '/content/drive/My Drive/Sentiment_Analysis/bbc_news_balanced_combined.txt'\n",
        "df_balanced['combined_fasttext_format_cleaned'].to_csv(balanced_output_file, index=False, header=False)"
      ],
      "metadata": {
        "id": "Y4-CRg9O3Yoa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the FastText model using the balanced dataset\n",
        "balanced_model = fasttext.train_supervised(\n",
        "    input=balanced_output_file,\n",
        "    lr=1.0,\n",
        "    epoch=25,\n",
        "    wordNgrams=2,\n",
        "    verbose=2,\n",
        "    minCount=1\n",
        ")\n",
        "\n",
        "# Save the balanced-trained model to a file\n",
        "balanced_model.save_model('/content/drive/My Drive/Sentiment_Analysis/bbc_news_balanced_model.bin')\n",
        "print(\"Balanced model trained and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVxDV2H-39g5",
        "outputId": "3a20a460-aa19-40be-81ce-e89d2217e0cc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced model trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions using the balanced model on the test dataset\n",
        "test_data['balanced_predictions'] = test_data['text_only'].apply(lambda x: balanced_model.predict(x)[0][0])\n",
        "\n",
        "# Generate the classification report with the predictions\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate the classification\n",
        "report = classification_report(test_data['label'], test_data['balanced_predictions'], target_names=['Negative', 'Neutral', 'Positive'], output_dict=True)\n",
        "\n",
        "# Extract the weighted precision and recall\n",
        "overall_precision = report['weighted avg']['precision']\n",
        "overall_recall = report['weighted avg']['recall']\n",
        "\n",
        "# Display the overall precision and recall\n",
        "print(f\"Overall Precision: {overall_precision}\")\n",
        "print(f\"Overall Recall: {overall_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9qeBbIq5YJa",
        "outputId": "93b074de-52af-4895-aab8-3f53fa8aeb22"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Precision: 0.9810387925588343\n",
            "Overall Recall: 0.9810336048879837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Get predictions for the test set\n",
        "test_data['balanced_predictions'] = test_data['text_only'].apply(lambda x: balanced_model.predict(x)[0][0])\n",
        "\n",
        "# Calculate and display the confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(test_data['label'], test_data['balanced_predictions'],\n",
        "                               labels=['__label__negative', '__label__neutral', '__label__positive'])\n",
        "print(\"Confusion Matrix After Balancing:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report After Balancing:\")\n",
        "print(classification_report(test_data['label'], test_data['balanced_predictions'],\n",
        "                            target_names=['Negative', 'Neutral', 'Positive']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi-q5Qr63-9d",
        "outputId": "b4d674f9-d67e-42f2-a361-ff1f4fd4dde5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix After Balancing:\n",
            "[[3539   13    2]\n",
            " [  63 1319   53]\n",
            " [   6   12 2849]]\n",
            "\n",
            "Classification Report After Balancing:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.98      1.00      0.99      3554\n",
            "     Neutral       0.98      0.92      0.95      1435\n",
            "    Positive       0.98      0.99      0.99      2867\n",
            "\n",
            "    accuracy                           0.98      7856\n",
            "   macro avg       0.98      0.97      0.97      7856\n",
            "weighted avg       0.98      0.98      0.98      7856\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "toBB1xhAFwR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcWoma3ykmBhWSM4OfyupL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}